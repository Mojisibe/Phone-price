{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QoNXHwBAiTA"
      },
      "outputs": [],
      "source": [
        "#Import Libraries\n",
        "import pymc as pm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import arviz as az\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Markdown, display\n",
        "from PIL import Image\n",
        "import csv\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5IOTSJpBJ5K",
        "outputId": "671322ce-f4ab-4b9f-cd76-ab9e7118f6bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pymc version: 5.21.2\n",
            "numpy version: 2.0.2\n",
            "pandas version: 2.2.2\n",
            "arviz version: 0.21.0\n",
            "matplotlib version: 3.10.0\n",
            "pymc version: 5.21.2\n",
            "numpy version: 2.0.2\n",
            "pandas version: 2.2.2\n",
            "arviz version: 0.21.0\n",
            "Python 3.11.11\n"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "# Check versions\n",
        "print(\"pymc version:\", pm.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"pandas version:\", pd.__version__)\n",
        "print(\"arviz version:\", az.__version__)\n",
        "print(\"matplotlib version:\", matplotlib.__version__)# Now access __version__ from matplotlib\n",
        "print(\"pymc version:\", pm.__version__)\n",
        "print(\"numpy version:\", np.__version__)\n",
        "print(\"pandas version:\", pd.__version__)\n",
        "print(\"arviz version:\", az.__version__)\n",
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4WlhEygBKbD"
      },
      "outputs": [],
      "source": [
        "def ordinal_predictor_binary_outcome_model_b02(predictor, outcome):\n",
        "    \"\"\"\n",
        "    PyMC model with a binary outcome and an ordinal predictor with a normal random walk constraint,\n",
        "    with fluctuations around an estimated effect.\n",
        "    Also includes PPCs, WAIC, and BIC calculation.\n",
        "    \"\"\"\n",
        "    with pm.Model() as model:\n",
        "        # Define the 'obs' dimension\n",
        "        n_obs = len(outcome)\n",
        "        model.add_coord(\"obs\", np.arange(n_obs))\n",
        "\n",
        "        # Priors\n",
        "        intercept = pm.Normal(\"intercept\", mu=0, sigma=10)\n",
        "        effect = pm.Normal(\"effect\", mu=0, sigma=2)\n",
        "        sd_fluctuation = pm.HalfCauchy(\"sd_fluctuation\", beta=2)\n",
        "\n",
        "        # Level effects differences\n",
        "        level_effects_diff = pm.Normal(\"level_effects_diff\", mu=effect, sigma=sd_fluctuation, shape=4)\n",
        "\n",
        "        # Cumulative level effects\n",
        "        level_effects = pm.Deterministic(\"level_effects\", pm.math.concatenate([[0], pm.math.cumsum(level_effects_diff)]))\n",
        "\n",
        "        # Linear predictor\n",
        "        logit_p = intercept + level_effects[predictor - 1]\n",
        "        p = pm.Deterministic(\"p\", pm.math.sigmoid(logit_p), dims=\"obs\")  # Dimension 'p' by 'obs'\n",
        "\n",
        "        # Likelihood - Associate observed data with 'obs' dimension\n",
        "        y_obs = pm.Bernoulli(\"y_obs\", p=p, observed=outcome, dims=\"obs\")\n",
        "\n",
        "        # Posterior predictive samples\n",
        "        y_pred = pm.Bernoulli(\"y_pred\", p=p, observed=None, dims=\"obs\")\n",
        "\n",
        "        # Sampling - Request log_likelihood\n",
        "        idata = pm.sample(\n",
        "            2000,\n",
        "            tune=1000,\n",
        "            return_inferencedata=True,\n",
        "            target_accept=0.9,  # Increased target_accept\n",
        "            idata_kwargs={\"log_likelihood\": True}  # Request log_likelihood\n",
        "        )\n",
        "        idata.extend(pm.sample_posterior_predictive(idata))\n",
        "\n",
        "        waic = az.waic(idata)\n",
        "        loo = az.loo(idata)\n",
        "\n",
        "        # BIC calculation\n",
        "        n_params = len(model.free_RVs)\n",
        "        log_likelihood = idata.log_likelihood.y_obs.values\n",
        "        bic = -2 * np.mean(log_likelihood) + n_params * np.log(n_obs)  # Use n_obs\n",
        "\n",
        "\n",
        "    return model, idata, waic, loo, bic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paclqMnUgeuj"
      },
      "outputs": [],
      "source": [
        "def run_and_summarize(data, model_func, label=\"b02\", output_dir=\"results\"):\n",
        "    \"\"\"\n",
        "    Runs the model, summarizes results, saves outputs: idata, summary, metrics, plots.\n",
        "    Works for B01 or B02 depending on the model_func provided.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    model, idata, waic, loo, bic = model_func(data[\"predictor\"], data[\"outcome\"])\n",
        "\n",
        "    # Save InferenceData\n",
        "    idata_path = os.path.join(output_dir, f\"idata_{label}.nc\")\n",
        "    idata.to_netcdf(idata_path)\n",
        "\n",
        "    # Determine var_names based on model\n",
        "    try:\n",
        "        # Check if variables like \"effect\" and \"sd_fluctuation\" exist (i.e. B02)\n",
        "        var_names = [\"intercept\", \"effect\", \"sd_fluctuation\", \"level_effects\", \"p\"]\n",
        "        _ = idata.posterior[\"effect\"]\n",
        "    except KeyError:\n",
        "        # B01 fallback\n",
        "        var_names = [\"intercept\", \"level_effects\", \"p\"]\n",
        "\n",
        "    # Save Summary\n",
        "    summary = az.summary(idata, var_names=var_names)\n",
        "    summary_path = os.path.join(output_dir, f\"summary_{label}.csv\")\n",
        "    summary.to_csv(summary_path)\n",
        "\n",
        "    # Save WAIC, LOO, BIC as a markdown file\n",
        "    metrics_path = os.path.join(output_dir, f\"model_metrics_{label}.md\")\n",
        "    with open(metrics_path, \"w\") as f:\n",
        "        f.write(f\"## Model {label.upper()} Metrics\\n\\n\")\n",
        "        f.write(\"### WAIC\\n\")\n",
        "        f.write(waic.to_string() + \"\\n\\n\")\n",
        "        f.write(\"### LOO\\n\")\n",
        "        f.write(loo.to_string() + \"\\n\\n\")\n",
        "        f.write(f\"### BIC\\nBIC = {bic:.2f}\\n\")\n",
        "\n",
        "    # Save Plots\n",
        "    trace_plot_path = os.path.join(output_dir, f\"trace_{label}.png\")\n",
        "    az.plot_trace(idata, var_names=[vn for vn in var_names if vn != \"p\"])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(trace_plot_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    posterior_plot_path = os.path.join(output_dir, f\"posterior_p_{label}.png\")\n",
        "    az.plot_posterior(idata, var_names=[\"p\"])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(posterior_plot_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    ppc_plot_path = os.path.join(output_dir, f\"ppc_{label}.png\")\n",
        "    az.plot_ppc(idata)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(ppc_plot_path, dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"✅ Saved all outputs for model {label.upper()} in '{output_dir}' folder.\")\n",
        "\n",
        "    return idata, waic, loo, bic\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdEHjCdH2Kgg"
      },
      "outputs": [],
      "source": [
        "# Data Generation\n",
        "def generate_test_data(n_per_level=100, random_seed=None):\n",
        "    rng = np.random.default_rng(random_seed)\n",
        "    predictor_levels = np.repeat(np.arange(1, 6), n_per_level)\n",
        "    probabilities = np.array([0.1, 0.2, 0.3, 0.4, 0.5])\n",
        "    true_probabilities = probabilities[predictor_levels - 1]\n",
        "    outcomes = rng.binomial(1, true_probabilities)\n",
        "    return pd.DataFrame({\"predictor\": predictor_levels, \"outcome\": outcomes})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "osrs9CP6gx5D",
        "outputId": "395cbc8a-6a5f-4456-8a83-df709f20f1c6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Sampling ... <span style=\"color: #008000; text-decoration-color: #008000\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> 0:00:00 / 0:00:01\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Sampling ... \u001b[32m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m 0:00:00 / 0:00:01\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/arviz/stats/diagnostics.py:596: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
            "/usr/local/lib/python3.11/dist-packages/arviz/stats/diagnostics.py:991: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  varsd = varvar / evar / 4\n",
            "/usr/local/lib/python3.11/dist-packages/arviz/stats/density_utils.py:488: UserWarning: Your data appears to have a single value or no finite values\n",
            "  warnings.warn(\"Your data appears to have a single value or no finite values\")\n",
            "/usr/local/lib/python3.11/dist-packages/arviz/plots/plot_utils.py:270: UserWarning: rcParams['plot.max_subplots'] (40) is smaller than the number of variables to plot (500) in plot_posterior, generating only 40 plots\n",
            "  warnings.warn(\n",
            "<ipython-input-15-ac14f60c543d>:53: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
            "  plt.tight_layout()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Saved all outputs for model B02 in 'results' folder.\n"
          ]
        }
      ],
      "source": [
        "# Generate test data\n",
        "test_data = generate_test_data(random_seed=42)\n",
        "\n",
        "# Run and save results for B02\n",
        "print(\"\\nResults for B02 Model:\")\n",
        "idata_b02, waic_b02, loo_b02, bic_b02 = run_and_summarize(test_data, ordinal_predictor_binary_outcome_model_b02, label=\"b02\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sUOt_dWOt8V"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "!zip -r results_b02.zip results/\n",
        "#files.download(\"results_b02.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "9jRyneHvNpPf",
        "outputId": "e2034451-bb96-4883-8da7-ecfc294e158b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'Bayesian-application-to-path-analysis/scripts/'\n",
            "/content\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06f51ccb-2a30-4329-922b-86d19b813279\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06f51ccb-2a30-4329-922b-86d19b813279\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7e60b2e2bbee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Upload the new clean notebook file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    165\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    166\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Make sure you're in the right repo folder\n",
        "%cd Bayesian-application-to-path-analysis/scripts/\n",
        "\n",
        "# Upload the new clean notebook file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da7-ETKkWDw5",
        "outputId": "ba5d2366-fe61-4b09-f73f-cc9a11bad0bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: -c: line 1: syntax error near unexpected token `('\n",
            "/bin/bash: -c: line 1: `git add Milestone_B02 (1).ipynb'\n",
            "fatal: not a git repository (or any of the parent directories): .git\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git add Milestone_B02 (1).ipynb\n",
        "!git commit -m \"Re-uploaded valid notebook\"\n",
        "!git push\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB2NYhIcOeIO",
        "outputId": "3c67c90c-875e-4882-e157-11689b7085b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@f960fe968a20.(none)')\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"Add the Bayesian model script to scripts folder\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KOoJcb4Oii3"
      },
      "outputs": [],
      "source": [
        "# Configure Git (only if not done yet)\n",
        "!git config --global user.email \"ogunjounb.o@gmail.com\"\n",
        "!git config --global user.name \"Mojisibe\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF2Nlb9IUVk0"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Securely enter your GitHub personal access token\n",
        "token = getpass('Enter your GitHub personal access token: ')\n",
        "\n",
        "# Replace with your GitHub username and repo name\n",
        "username = \"your-username\"\n",
        "repo_name = \"your-private-repo\"\n",
        "\n",
        "# Correctly formatted HTTPS URL\n",
        "repo_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n",
        "\n",
        "# Clone the repo\n",
        "!git clone {repo_url}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1f3dAkF7TODw",
        "outputId": "fc8fe3fb-6241-4fef-f2dc-939a3320358c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your GitHub personal access token: ··········\n",
            "Cloning into 'Bayesian-application-to-path-analysis}'...\n",
            "fatal: protocol '{https' is not supported\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "# Paste your personal access token here\n",
        "token = getpass('Enter your GitHub personal access token: ')\n",
        "\n",
        "# Replace with your repo info\n",
        "username = \"Mojisibe\"\n",
        "repo_name = \"Bayesian-application-to-path-analysis\"\n",
        "repo_url = f\"https://{token}@github.com/{username}/{repo_name}.git\"\n",
        "\n",
        "!git clone {https://github.com/Mojisibe/Bayesian-application-to-path-analysis}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFj2yFgPOu5y",
        "outputId": "444aea4a-c0bf-4a0d-8036-2d1d1bf5f801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ],
      "source": [
        "!git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjfN4nBlGfVW"
      },
      "outputs": [],
      "source": [
        "mv scripts/'Bayesian model with test data.py' scripts/Milestone_B02.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k792_KiCu-5j"
      },
      "outputs": [],
      "source": [
        "!git add scripts/Milestone_B02.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPy1DD-zvRk4",
        "outputId": "924694a5-0ae9-407f-d15e-11b0995333f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main d065b92] Rename and add the Bayesian model script with the correct name\n",
            " 1 file changed, 0 insertions(+), 0 deletions(-)\n",
            " rename scripts/{Bayesian model with test data.py => Milestone_B02.ipynb} (100%)\n"
          ]
        }
      ],
      "source": [
        "!git commit -m \"Rename and add the Bayesian model script with the correct name\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpvnuHE5R0Mb",
        "outputId": "7f1a35e5-891f-4acb-ac94-88bbd1a815d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 5, done.\n",
            "Counting objects:  20% (1/5)\rCounting objects:  40% (2/5)\rCounting objects:  60% (3/5)\rCounting objects:  80% (4/5)\rCounting objects: 100% (5/5)\rCounting objects: 100% (5/5), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects:  50% (1/2)\rCompressing objects: 100% (2/2)\rCompressing objects: 100% (2/2), done.\n",
            "Writing objects:  33% (1/3)\rWriting objects:  66% (2/3)\rWriting objects: 100% (3/3)\rWriting objects: 100% (3/3), 337 bytes | 337.00 KiB/s, done.\n",
            "Total 3 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/Mojisibe/Bayesian-application-to-path-analysis.git\n",
            "   6c0e22c..d065b92  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git push origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UFGA-tYAvElb"
      },
      "outputs": [],
      "source": [
        "# Copy your main script\n",
        "!cp \"/content/Bayesian-application-to-path-analysis/Bayesian model with test data.py\" \"/content/Bayesian-application-to-path-analysis/scripts/\"\n",
        "\n",
        "# Copy the entire 'results' folder\n",
        "!cp -r /content/results /content/Bayesian-application-to-path-analysis/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy4YvjToQcVX",
        "outputId": "eb9d3836-db9d-48aa-cb54-69170e0dbc86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Bayesian-application-to-path-analysis\n",
            "[main 993ef02] Add B02 model script and results\n",
            " 7 files changed, 616 insertions(+)\n",
            " create mode 100644 results/idata_b02.nc\n",
            " create mode 100644 results/model_metrics_b02.md\n",
            " create mode 100644 results/posterior_p_b02.png\n",
            " create mode 100644 results/ppc_b02.png\n",
            " create mode 100644 results/summary_b02.csv\n",
            " create mode 100644 results/trace_b02.png\n",
            " create mode 100644 scripts/Bayesian model with test data.py\n",
            "Enumerating objects: 11, done.\n",
            "Counting objects: 100% (11/11), done.\n",
            "Delta compression using up to 2 threads\n",
            "Compressing objects: 100% (10/10), done.\n",
            "Writing objects: 100% (10/10), 7.39 MiB | 4.71 MiB/s, done.\n",
            "Total 10 (delta 1), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\n",
            "To https://github.com/Mojisibe/Bayesian-application-to-path-analysis.git\n",
            "   f15a66c..993ef02  main -> main\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Bayesian-application-to-path-analysis\n",
        "\n",
        "# Configure Git (only if not done yet)\n",
        "!git config --global user.email \"ogunjounb.o@gmail.com\"\n",
        "!git config --global user.name \"Mojisibe\"\n",
        "\n",
        "# Stage changes\n",
        "!git add .\n",
        "\n",
        "# Commit with a message\n",
        "!git commit -m \"Add B02 model script and results\"\n",
        "\n",
        "# Push to GitHub\n",
        "!git push origin main\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59m8XJ3vUrp9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}